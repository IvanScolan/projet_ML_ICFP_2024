{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# PyTorch uses 'nn.Module' as the base class for all neural network modules.\n",
    "class TBHNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Tight-binding Hamiltonian neural network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TBHNN, self).__init__()\n",
    "        self.H_size_added = 0\n",
    "        # We will add more attributes and initializations as we convert other methods\n",
    "\n",
    "    # Placeholder for read_training_set method, will be filled in later\n",
    "    def read_training_set(self, references, k_vectors):\n",
    "        num_k, num_b = references.shape\n",
    "        self.num_b = num_b\n",
    "        self.num_k = num_k\n",
    "        self.H_size_init = num_b\n",
    "        self.H_size = num_b\n",
    "        self.references = torch.tensor(references, dtype=torch.float32, requires_grad=True)\n",
    "        self.k_vectors = torch.tensor(k_vectors, dtype=torch.float32, requires_grad=True)\n",
    "        # In PyTorch, tensors are automatically placed on the default device, so we don't\n",
    "        # need to explicitly define device placement as in TensorFlow\n",
    "        pass\n",
    "\n",
    "    # Placeholder for define_TB_representation method, will be filled in later\n",
    "    def define_TB_representation(self, vectors_without_opposite):\n",
    "        # In PyTorch, we usually do not need to cast to complex inside class methods,\n",
    "        # unless it is necessary for certain operations.\n",
    "        num_r = len(vectors_without_opposite)\n",
    "        self.num_r = num_r\n",
    "        self.R = torch.nn.Parameter(torch.zeros((num_r, 3), dtype=torch.float32))\n",
    "\n",
    "        # Then you can create a new tensor for R without in-place operations\n",
    "        new_R_values = []\n",
    "        for i, vector in enumerate(vectors_without_opposite):\n",
    "            if not np.all(np.isclose(vector, 0.0)):\n",
    "                new_R_values.append(torch.tensor(vector, dtype=torch.float32))\n",
    "            else:\n",
    "                new_R_values.append(torch.zeros(3, dtype=torch.float32))\n",
    "\n",
    "        # Now you can concatenate the list of tensors into a single tensor\n",
    "        new_R = torch.stack(new_R_values)\n",
    "\n",
    "        # If 'self.R' needs to maintain its gradient, you should replace it with 'new_R' like so:\n",
    "        self.R = torch.nn.Parameter(new_R)\n",
    "\n",
    "        self.R_without_opposite = vectors_without_opposite\n",
    "\n",
    "        pass\n",
    "\n",
    "    # Placeholder for reinitialize method, will be filled in later\n",
    "    def reinitialize(self):\n",
    "        self.H_R = torch.nn.ParameterList()  # Use ParameterList instead of ModuleList\n",
    "        self.H_size = self.H_size_init + self.H_size_added\n",
    "        \n",
    "        for _ in self.R_without_opposite:\n",
    "            H_tmp = torch.nn.Parameter(torch.randn((self.H_size, self.H_size), dtype=torch.float32) * 0.1)\n",
    "            self.H_R.append(H_tmp)\n",
    "        pass\n",
    "\n",
    "    # Placeholder for compute_bands method, will be filled in later\n",
    "    def compute_bands(self):\n",
    "        reproduced_bands = torch.zeros((self.num_k, self.H_size), dtype=torch.float32)\n",
    "        \n",
    "        for i in range(self.num_k):\n",
    "            K = torch.zeros((self.H_size, self.H_size), dtype=torch.complex64)\n",
    "            for j, H_R_component in enumerate(self.H_R):\n",
    "                exp_factor = torch.exp(-1j * np.pi * torch.matmul(self.k_vectors[i], self.R[j]))\n",
    "                K += exp_factor * H_R_component\n",
    "                \n",
    "            # Eigenvalues are computed from the Hermitian part of K to ensure they are real\n",
    "            eigenvalues, _ = torch.linalg.eigh(K + K.conj().T)\n",
    "            reproduced_bands[i] = eigenvalues.real\n",
    "\n",
    "        # Sort the bands and discard those not needed for loss computation\n",
    "        reproduced_bands = reproduced_bands[:, :self.H_size_init]\n",
    "        self.bandstructure = reproduced_bands\n",
    "\n",
    "        return reproduced_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TBHCNN_stochastic_reset(mean_reset,threshold,stochastic):\n",
    "\n",
    "    rvectors_without_opposite = np.array([[0,0,0],[0,0,1],], dtype=np.int32) # in units of[a, b, c] (a, b, and c are the real-space basis vectors; [l, n, m] means the lattice vector l*a+n*b+m*c)\n",
    "    # Load training data\n",
    "    references = np.load(\"./data/input/InSe Nanoribbon/InSe-references.npy\")\n",
    "    k_vectors = np.load(\"./data/input/InSe Nanoribbon/InSe-kpoints.npy\") # in units of 1/2pi*[ak, bk, ck] (ak, bk, and ck are the corresponding k-space basis vectors; [l, n, m] means the k-vector (l/2pi)*ak+(n/2pi)*bk+(m/2pi)*ck)\n",
    "\n",
    "\n",
    "    # Initialize the model\n",
    "    tbhnn = TBHNN()\n",
    "    tbhnn.read_training_set(references, k_vectors)\n",
    "    tbhnn.define_TB_representation(rvectors_without_opposite)\n",
    "\n",
    "    Loss_history = []\n",
    "    resettings = [0]\n",
    "\n",
    "    print(f\"Threshold = {threshold}\")\n",
    "    print(f\"Average # step until resetting = {mean_reset}\")\n",
    "    print(f\"Stochastic resetting ? {stochastic}\")\n",
    "\n",
    "    finished = False\n",
    "\n",
    "    while not finished:\n",
    "        tbhnn.reinitialize()\n",
    "        optimizer = torch.optim.Adam(tbhnn.parameters(), lr=0.001)\n",
    "\n",
    "        step_reset = int(mean_reset)\n",
    "        \n",
    "        if stochastic:\n",
    "            step_reset = int(np.random.exponential(mean_reset))\n",
    "        \n",
    "        resettings.append(resettings[-1]+step_reset)\n",
    "\n",
    "        for step in range(0,step_reset):\n",
    "            optimizer.zero_grad()\n",
    "            reproduced_bands = tbhnn.compute_bands()\n",
    "            loss = torch.nn.SmoothL1Loss()(reproduced_bands, tbhnn.references)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            Loss_history.append(loss.item())\n",
    "\n",
    "            # if step % 1000 == 0:\n",
    "            #     print(f\"Step {step+resettings[-2]}, Loss: {loss.item()}\")\n",
    "\n",
    "            if loss.item() < threshold:\n",
    "                finished = True\n",
    "                resettings.pop()\n",
    "                print(f\"Convergence reached at step {resettings[-1]+step} for mean resetting step {mean_reset}\")\n",
    "                break\n",
    "\n",
    "     \n",
    "    #epochs visu. & Loss Function History plot\n",
    "    \"\"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(Loss_history, label = f\"Convergence at step {np.max(Loss_history)}\")\n",
    "    plt.title(f\"Loss Function History for lambda = {mean_reset} (Stochastic ? {stochastic})\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss function value\")\n",
    "    plt.vlines(resettings,ymin=0.,ymax=np.max(Loss_history),linestyles=\"--\",color=\"red\",label=\"(Re)settings\")\n",
    "    #plt.legend()\n",
    "    #plt.ylim(bottom=np.min(Loss_history),top=0.005)\n",
    "    folder_name = \"Loss_plots\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    filename = os.path.join(folder_name, f\"losses_{threshold}_{stochastic}_{mean_reset}_{len(Loss_history)}.jpg\")\n",
    "    plt.savefig(filename, format='jpg')\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    return(reproduced_bands,len(Loss_history))\n",
    "    \n",
    "    \n",
    "    # Save the model if needed\n",
    "    # torch.save(tbhnn.state_dict(), \"path_to_model.pt\")\n",
    "\n",
    "#reproduced_bands, convergence = TBHCNN_stochastic_reset(500,1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.005\n",
      "Average # step until resetting = 3000.0\n",
      "Stochastic resetting ? True\n",
      "Convergence reached at step 1180 for mean resetting step 3000.0\n",
      "Threshold = 0.005\n",
      "Average # step until resetting = 3000.0\n",
      "Stochastic resetting ? False\n",
      "Convergence reached at step 867 for mean resetting step 3000.0\n",
      "Threshold = 0.005\n",
      "Average # step until resetting = 3000.0\n",
      "Stochastic resetting ? True\n",
      "Convergence reached at step 808 for mean resetting step 3000.0\n",
      "Threshold = 0.005\n",
      "Average # step until resetting = 3000.0\n",
      "Stochastic resetting ? False\n",
      "Convergence reached at step 795 for mean resetting step 3000.0\n",
      "Threshold = 0.005\n",
      "Average # step until resetting = 3000.0\n",
      "Stochastic resetting ? True\n",
      "Convergence reached at step 866 for mean resetting step 3000.0\n",
      "Threshold = 0.005\n",
      "Average # step until resetting = 3000.0\n",
      "Stochastic resetting ? False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Samples):\n\u001b[0;32m     14\u001b[0m         convergences_sto[k,s] \u001b[38;5;241m=\u001b[39m TBHCNN_stochastic_reset(mean,threshold,stochastic)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m         convergences_deter[k,s] \u001b[38;5;241m=\u001b[39m \u001b[43mTBHCNN_stochastic_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     17\u001b[0m mean_convergences_sto \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(convergences_sto[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nb_means)]\n\u001b[0;32m     18\u001b[0m mean_convergences_deter \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(convergences_deter[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nb_means)]\n",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m, in \u001b[0;36mTBHCNN_stochastic_reset\u001b[1;34m(mean_reset, threshold, stochastic)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,step_reset):\n\u001b[0;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 36\u001b[0m     reproduced_bands \u001b[38;5;241m=\u001b[39m \u001b[43mtbhnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_bands\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSmoothL1Loss()(reproduced_bands, tbhnn\u001b[38;5;241m.\u001b[39mreferences)\n\u001b[0;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[4], line 74\u001b[0m, in \u001b[0;36mTBHNN.compute_bands\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, H_R_component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH_R):\n\u001b[0;32m     73\u001b[0m     exp_factor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_vectors[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR[j]))\n\u001b[1;32m---> 74\u001b[0m     K \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m exp_factor \u001b[38;5;241m*\u001b[39m H_R_component\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Eigenvalues are computed from the Hermitian part of K to ensure they are real\u001b[39;00m\n\u001b[0;32m     77\u001b[0m eigenvalues, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(K \u001b[38;5;241m+\u001b[39m K\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39mT)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold = 1e-3\n",
    "Samples = 15\n",
    "Nb_means = 30\n",
    "stochastic = True\n",
    "deterministic = False\n",
    "\n",
    "means = np.linspace(2000,20000,Nb_means)\n",
    "\n",
    "convergences_sto = np.zeros([Nb_means,Samples],dtype=int)\n",
    "convergences_deter = convergences_sto.copy()\n",
    "\n",
    "for k,mean in enumerate(means):\n",
    "    for s in range(Samples):\n",
    "        convergences_sto[k,s] = TBHCNN_stochastic_reset(mean,threshold,stochastic)[1]\n",
    "        convergences_deter[k,s] = TBHCNN_stochastic_reset(mean,threshold,deterministic)[1]\n",
    "\n",
    "mean_convergences_sto = [np.mean(convergences_sto[i]) for i in range(Nb_means)]\n",
    "mean_convergences_deter = [np.mean(convergences_deter[i]) for i in range(Nb_means)]\n",
    "std_sto = [np.std(convergences_sto[i]) for i in range(Nb_means)]\n",
    "std_deter = [np.std(convergences_deter[i]) for i in range(Nb_means)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_convergences_sto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m std_sto \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mstd(convergences_sto[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nb_means)]\n\u001b[0;32m      2\u001b[0m std_deter \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mstd(convergences_deter[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nb_means)]\n\u001b[1;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39merrorbar(means,\u001b[43mmean_convergences_sto\u001b[49m,yerr\u001b[38;5;241m=\u001b[39mstd_sto,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStochastic resetting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39merrorbar(means,mean_convergences_deter,yerr\u001b[38;5;241m=\u001b[39mstd_deter,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeterministic resetting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of Poissonian Resetting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_convergences_sto' is not defined"
     ]
    }
   ],
   "source": [
    "plt.errorbar(means,mean_convergences_sto,yerr=std_sto,label=\"Stochastic resetting\")\n",
    "plt.errorbar(means,mean_convergences_deter,yerr=std_deter,label=\"Deterministic resetting\")\n",
    "plt.xlabel(\"Mean of Poissonian Resetting\")\n",
    "plt.ylabel(\"Convergence (step)\")\n",
    "plt.title(f\"Convergence vs Resetting rate at $\\epsilon=${threshold}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With paper's parameters\n",
    "\n",
    "# stochastic = False\n",
    "# threshold = 1e-5\n",
    "# reproduced_bands_instance, Conv_time = TBHCNN_stochastic_reset(10000,threshold,stochastic)\n",
    "\n",
    "# reproduced_bands_np = reproduced_bands_instance.detach().numpy()\n",
    "# for band in range(reproduced_bands_np.shape[1]):\n",
    "#     plt.plot(reproduced_bands_np[:, band], label=f'Band {band+1}')\n",
    "\n",
    "# plt.xlabel('k-point Index')\n",
    "# plt.ylabel('Energy')\n",
    "# plt.title('Band Structure')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
